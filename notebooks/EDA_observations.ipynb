{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Whatch out where the foxes go,\n",
    "And don't you eat the yellow snow\"\n",
    "\n",
    "Whoever wrote does line does not know half as much about Data-Scientific Research (DSR) on Polar Foxes as I first thought, when I agreed to join this digital expedition.\n",
    "\n",
    "But first things first: \n",
    "This is me, Florian Hofmann, your Storytelling Data Scientist.\n",
    "\n",
    "And it seems like yesterday that I agreed to join scientific researches on habitat selection of Arctic Foxes.\n",
    "But now as I'm writing those lines, this fateful decision already lies about 2 months in the past.\n",
    "\n",
    "\n",
    "And what you are reading right now is my personal notebook of our mission to \"predict and protect\" where Arctic Foxes live."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As my grandma used to say.\n",
    "\n",
    "\"Never travel to the tundra without some freshly imported Python libraries\".\n",
    "\n",
    "As we had no reasons to doubt those, this is just what we did.\n",
    "\n",
    "So our backpacks included the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../modeling\")\n",
    "\n",
    "import home_ranges as hr\n",
    "import features_for_observations as f4o\n",
    "\n",
    "from keplergl import KeplerGl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as geopd\n",
    "import seaborn as sns\n",
    "import datetime as dt \n",
    "\n",
    "from rasterio.plot import show\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from shapely.geometry import Polygon\n",
    "import shapely\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next obvious step consisted in getting as much information of the Tundra as we could possibly get.\n",
    "\n",
    "Which definitely was not much.\n",
    "\n",
    "All we had was \n",
    "- a dataset with GPS data of 12 foxes, with the foxes' ID number, sex, and of course timestamp and coordinates\n",
    "- a dataset with fox dens in the whole area. Unfortunately, as Foxes don't put name tags next to their doors, it was not really obvious which fox was living where\n",
    "- a dataset of sample points in our research area.\n",
    "\n",
    "Even if it was not much, I was glad that my expedition members had already done a great job at gathering and cleaning the data, because when I started using it, it proved to be in perfect condition:\n",
    "No missing values, no duplicates, just plain condensed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_all = geopd.read_file(\"../data/cleaned_shapefiles/foxes_all.shp\")\n",
    "sample_points = geopd.read_file(\"../data/cleaned_shapefiles/sample_points.shp\")\n",
    "dens_all = geopd.read_file(\"../data/cleaned_shapefiles/dens_norrbotten.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we hit our first cultural and linguistic barrier:\n",
    "\n",
    "The GPS data of the foxes was in the Swedish coordinate system known as CRS3006.\n",
    "\n",
    "In order to facilitate handling, I included as addidtional rows the same coordinates that were the only ones our good friend Kepler GL was able to understand - EPSG4326."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = foxes_all.geometry\n",
    "gdf = gpd.GeoDataFrame(test, crs=3006)\n",
    "\n",
    "gdf = gdf.to_crs(epsg= 4326)\n",
    "\n",
    "foxes_all[\"geo_kepler_lat\"] = [geo.y for geo in gdf.geometry]\n",
    "foxes_all[\"geo_kepler_lon\"] = [geo.x for geo in gdf.geometry]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for some Data-Based Storytelling, I deemed it necessary to insert some temporal information:\n",
    "\n",
    "First at all, as we knew Polar Foxes to be nocturnal, we wanted to look at days \"as the fox does\".\n",
    "\n",
    "More practically, we introduced the concept of a \"fox day\", going from noon to noon of a \"human day\".\n",
    "This would allow us to represent fox activity based on their cycle of activity.\n",
    "\n",
    "Also I introduced columns that extracted the month and the year of the timestamp, as to better group by those time categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_all[\"fox_day\"] = [str(datetime.strptime(x, '%Y-%m-%d-%H:%M:%S' ) + timedelta(hours=12))[:10]  for x in foxes_all.t_ ]\n",
    "\n",
    "foxes_all[\"month\"] = [x[5:7] for x in foxes_all.fox_day]\n",
    "foxes_all[\"year\"] = [x[:4] for x in foxes_all.fox_day]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this finger exercise, which was just perfect with the cold wind in the tundra, I went for some slightly advanced feature engineering:\n",
    "As our DataFrame foxes_all contained GPS data in combination with time stamps, we decided it would be helpful to know the temporal and spatial differences for to subsequent data points of the same fox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_all[\"travel_distance\"] = f4o.get_distance(foxes_all)\n",
    "foxes_all[\"time_diff\"] = f4o.get_time_diffs(foxes_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By know, it turned out that our data on foxes was somewhat sparse. While on some days, we had Data Points about every 15 minutes, other days barely included data points at all.\n",
    "\n",
    "So I included into the table two more columns that for each \"fox day\" counted the number of data points (the more, the more information that day), and the maximum time delta between to data points on this day (the less, the more precise the information that day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_day = foxes_all[[\"id\", \"time_diff\", \"fox_day\"]].groupby([\"id\",\"fox_day\"], as_index=False ).count().rename(columns={\"time_diff\": \"points_this_day\"})\n",
    "\n",
    "max_window_per_day = foxes_all[[\"id\", \"time_diff\", \"fox_day\"]].groupby([\"id\",\"fox_day\"], as_index=False ).max().rename(columns={\"time_diff\": \"max_window\"})\n",
    "\n",
    "foxes_all_temp = pd.merge( foxes_all, points_per_day, left_on=[\"id\", \"fox_day\"], right_on=[\"id\", \"fox_day\"] )\n",
    "foxes_all_2 = pd.merge( max_window_per_day, foxes_all_temp , left_on=[\"id\", \"fox_day\"], right_on=[\"id\", \"fox_day\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = pd.DataFrame(columns=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "y = foxes_all.groupby([\"id\", \"sex\"], as_index=False).count()[[\"id\",\"sex\"]]\n",
    "\n",
    "#for z in y.id:\n",
    " #   print(z)\n",
    "#y[\"geometry\"] = [polygon_to_geojson(hr.hr_area(foxes_all.query('id ==@x'))) for x in y.id ]\n",
    "y[\"hr_area\"] = [hr.hr_area(foxes_all.query('id ==@x')).area for x in y.id ]\n",
    "#y.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.hr_area.min() / y.hr_area.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "circle_all = Polygon()\n",
    "hr_all = Polygon()\n",
    "intersect_all = Polygon()\n",
    "map1=KeplerGl(height=500)\n",
    "\n",
    "cols_df = [\"id\", \"geo_kepler_lat\", \"geo_kepler_lon\"]\n",
    "cols_geo = ['fox_day']\n",
    "\n",
    "\n",
    "for fox_id in foxes_all.query(\"id == '2019-FSBD609-002' and month == '08' and year =='2019' and fox_day < '2019-09-01' \").id.unique():    \n",
    "    fox_hr_poly = hr.hr_area(foxes_all.query(\"id == '2019-FSBD609-002' and month == '08' and year =='2019' and fox_day < '2019-09-01' \"))\n",
    "  #  den = foxes_all.query('id ==@fox_id')[[\"id\", \"geo_round\", \"t_\"]].groupby([\"id\", \"geo_round\"], as_index=False).count().sort_values(by=\"t_\").tail(1).geo_round \n",
    "    #den_coord = Point(tuple(den)[0][0] , tuple(den)[0][1] )\n",
    "    #circle = den_coord.buffer(max_dist_point_poly(den_coord, fox_hr_poly))\n",
    "  #  x = hr_all.intersection(fox_hr_poly)\n",
    "   # intersect_all = intersect_all.union(x)\n",
    "   # circle_all = circle_all.union(circle)\n",
    "    #hr_all = hr_all.union(fox_hr_poly)\n",
    "    geojson = f4o.df_to_geojson_trip(foxes_all.query(\"id == '2019-FSBD609-002' and month == '08' and year =='2019' and fox_day < '2019-09-01' \"), cols_geo)\n",
    "   # map1.add_data(data= foxes_all.query(\"id == '2019-FSBD609-002' and month == '08' and year =='2019'\")[cols_df], name = \"where did the fox go\")\n",
    "    map1.add_data(data=geojson,name='Where does fox  ' + fox_id + ' trot?')\n",
    "\n",
    "  \n",
    "    \n",
    "    #map1.add_data(data=g(den_coord, columns=\"geometry\"), name = \"center\" + fox_id)\n",
    "    map1.add_data(data = f4o.polygon_to_geojson(fox_hr_poly), name='homerange' + fox_id)\n",
    "    #map1.add_data(data = polygon_to_geojson(circle), name=\"circle\" + fox_id)\n",
    "\n",
    "\n",
    "map1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_points_by_hr_with_id = pd.DataFrame(columns=[\"geometry\", \"id\"])\n",
    "\n",
    "for fox_id in foxes_all.id.unique():\n",
    "    points = sample_points.intersection(hr.hr_area(foxes_all.query('id ==@fox_id')))\n",
    "    df_temp = pd.DataFrame(columns=[\"geometry\"], data=points[~points.is_empty].to_list())\n",
    "    df_temp[\"id\"] = fox_id\n",
    "    sample_points_by_hr_with_id = pd.concat([sample_points_by_hr_with_id, df_temp ])\n",
    "\n",
    "sample_points_in_hr_with_id = sample_points_by_hr_with_id.drop_duplicates().merge(sample_points, on = \"geometry\")\n",
    "\n",
    "a = sample_points_in_hr_with_id[[\"id\", \"soil\", \"veg\"]].groupby([\"id\", \"veg\"], as_index=False).count()\n",
    "b = sample_points_in_hr_with_id[[\"id\", \"soil\", \"veg\"]].groupby([\"id\", \"soil\"], as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_day = foxes_all[[\"id\", \"time_diff\", \"fox_day\"]].groupby([\"id\",\"fox_day\"], as_index=False ).count().rename(columns={\"time_diff\": \"points_this_day\"})\n",
    "\n",
    "max_window_per_day = foxes_all[[\"id\", \"time_diff\", \"fox_day\"]].groupby([\"id\",\"fox_day\"], as_index=False ).max().rename(columns={\"time_diff\": \"max_window\"})\n",
    "\n",
    "foxes_all_temp = pd.merge( foxes_all,points_per_day, left_on=[\"id\", \"fox_day\"], right_on=[\"id\", \"fox_day\"] )\n",
    "foxes_all = pd.merge( foxes_all_temp, max_window_per_day,  left_on=[\"id\", \"fox_day\"], right_on=[\"id\", \"fox_day\"] )\n",
    "\n",
    "foxes_relevant_days = foxes_all.query(\"max_window < 1000 and points_this_day > 80\")\n",
    "\n",
    "#for rel_day in foxes_relevant_days:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_relevant_days = foxes_all.query(\"max_window < 2000 and points_this_day > 40\") #.groupby([\"id\", \"fox_day\"]).count()\n",
    "len(foxes_relevant_days.fox_day.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_relevant_days[[\"id\", \"fox_day\",\"travel_distance\"] ].groupby([\"id\", \"fox_day\"]).sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "foxes_poly_day = gpd.GeoDataFrame(\n",
    "    foxes_relevant_days[[\"id\", \"fox_day\", \"x_\", \"y_\"]].groupby([\"id\", \"fox_day\"], as_index=False).apply(\n",
    "        lambda d: pd.Series(\n",
    "            {\n",
    "   #             \"name\": \"|\".join(d[\"name\"].tolist()),\n",
    "                \"geometry\": shapely.geometry.Polygon(\n",
    "                    d.loc[:, [\"x_\", \"y_\"]].values\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    ")\n",
    "foxes_poly_day.eval( \"trip_area = geometry.area / 1000000\", inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = foxes_relevant_days[[\"id\", \"fox_day\", \"month\",\"travel_distance\"]].groupby([\"id\", \"fox_day\", \"month\"], as_index=False).sum()\n",
    "\n",
    "d = c[[ \"month\", \"travel_distance\"]].groupby([ \"month\"]).agg([np.min, np.max, np.mean, np.median, np.count_nonzero ], as_index=False)\n",
    "d\n",
    "#foxes_all.query(\"month == '01'\")\n",
    "#c.query(\"id == '2019-FSBD609-002' and month == '08'\")\n",
    "foxes_all.query(\"month == '09'\").fox_day.value_counts().sort_index()\n",
    "foxes_all.query(\"month == '09'\")[[\"id\",\"year\"]].groupby([\"id\", \"year\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_relevant_days[[\"id\",\"sex\", \"travel_distance\", \"fox_day\", \"month\"]].groupby([\"id\",\"sex\", \"month\",  \"fox_day\"], as_index=False).sum()\n",
    "\n",
    "foxes_all.points_this_day.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_poly_day.geometry[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_id = '2018-FSBD619_r-gr/r-y'\n",
    "\n",
    "map2 = KeplerGl(height=500)\n",
    "#map2.add_data(polygon_to_geojson( hr.hr_area(foxes_all.query('id ==@fox_id')) ), name = \"hr\")\n",
    "map2.add_data(data = dens_all, name = \"dens\")\n",
    "i = 0\n",
    "for x in foxes_poly_day.query(\"id ==@fox_id\")[:3].geometry:\n",
    "    map2.add_data(f4o.polygon_to_geojson(x), name = \"hr_\" + str(i))\n",
    "    i+=1\n",
    "    \n",
    "\n",
    "map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_poly_day.id.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88fcde65eaa45fa38563b1be78b27e061faa45edeabc7876995c133cb7644015"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
