{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Whatch out where the foxes go,\n",
    "And don't you eat the yellow snow\"\n",
    "\n",
    "Whoever wrote does line does not know half as much about Data-Scientific Research (DSR) on Polar Foxes as I first thought, when I agreed to join this digital expedition.\n",
    "\n",
    "But first things first: \n",
    "This is me, Florian Hofmann, your Storytelling Data Scientist.\n",
    "\n",
    "And it seems like yesterday that I agreed to join scientific researches on habitat selection of Arctic Foxes.\n",
    "But now as I'm writing those lines, this fateful decision already lies about 2 months in the past.\n",
    "\n",
    "\n",
    "And what you are reading right now is my personal notebook of our mission to \"predict and protect\" where Arctic Foxes live."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As my grandma used to say:\n",
    "\n",
    "\"Never travel to the tundra without some freshly imported Python libraries\".\n",
    "\n",
    "As we had no reasons to doubt those, this is just what we did.\n",
    "\n",
    "So our backpacks included the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../modeling\")\n",
    "\n",
    "import home_ranges as hr\n",
    "import features_for_observations as f4o\n",
    "\n",
    "from keplergl import KeplerGl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as geopd\n",
    "import seaborn as sns\n",
    "import datetime as dt \n",
    "\n",
    "from rasterio.plot import show\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from shapely.geometry import Polygon\n",
    "import shapely\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next obvious step consisted in getting as much information of the Tundra as we could possibly get.\n",
    "\n",
    "Which definitely was not much.\n",
    "\n",
    "All we had was \n",
    "- a dataset with GPS data of 12 foxes, with the foxes' ID number, sex, and of course timestamp and coordinates\n",
    "- a dataset with fox dens in the whole area. Unfortunately, as Foxes don't put name tags next to their doors, it was not really obvious which fox was living where\n",
    "- a dataset of sample points in our research area.\n",
    "\n",
    "Even if it was not much, I was glad that my expedition members had already done a great job at gathering and cleaning the data, because when I started using it, it proved to be in perfect condition:\n",
    "No missing values, no duplicates, just plain condensed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_all = geopd.read_file(\"../data/cleaned_shapefiles/foxes_all.shp\")\n",
    "sample_points = geopd.read_file(\"../data/cleaned_shapefiles/sample_points.shp\")\n",
    "dens_all = geopd.read_file(\"../data/cleaned_shapefiles/dens_norrbotten.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we hit our first cultural and linguistic barrier:\n",
    "\n",
    "The GPS data of the foxes was in the Swedish coordinate system known as CRS3006.\n",
    "\n",
    "In order to facilitate handling, I included as addidtional rows the same coordinates that were the only ones our good friend Kepler GL was able to understand - EPSG4326."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = foxes_all.geometry\n",
    "gdf = gpd.GeoDataFrame(test, crs=3006)\n",
    "\n",
    "gdf = gdf.to_crs(epsg= 4326)\n",
    "\n",
    "foxes_all[\"geo_kepler_lat\"] = [geo.y for geo in gdf.geometry]\n",
    "foxes_all[\"geo_kepler_lon\"] = [geo.x for geo in gdf.geometry]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for some Data-Based Storytelling, I deemed it necessary to insert some temporal information:\n",
    "\n",
    "First at all, as we knew Polar Foxes to be nocturnal, we wanted to look at days \"as the fox does\".\n",
    "\n",
    "More practically, we introduced the concept of a \"fox day\", going from noon to noon of a \"human day\".\n",
    "This would allow us to represent fox activity based on their cycle of activity.\n",
    "\n",
    "Also I introduced columns that extracted the month and the year of the timestamp, as to better group by those time categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_all[\"fox_day\"] = [str(datetime.strptime(x, '%Y-%m-%d-%H:%M:%S' ) + timedelta(hours=12))[:10]  for x in foxes_all.t_ ]\n",
    "\n",
    "foxes_all[\"month\"] = [x[5:7] for x in foxes_all.fox_day]\n",
    "foxes_all[\"year\"] = [x[:4] for x in foxes_all.fox_day]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this finger exercise, which was just perfect with the cold wind in the tundra, I went for some slightly advanced feature engineering:\n",
    "As our DataFrame foxes_all contained GPS data in combination with time stamps, we decided it would be helpful to know the temporal and spatial differences for to subsequent data points of the same fox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_all[\"travel_distance\"] = f4o.get_distance(foxes_all)\n",
    "foxes_all[\"time_diff\"] = f4o.get_time_diffs(foxes_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By know, it turned out that our data on foxes was somewhat sparse. While on some days, we had Data Points about every 15 minutes, other days barely included data points at all.\n",
    "\n",
    "So I included into the table two more columns that for each \"fox day\" counted the number of data points (the more, the more information that day), and the maximum time delta between to data points on this day (the less, the more precise the information that day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_day = foxes_all[[\"id\", \"time_diff\", \"fox_day\"]].groupby([\"id\",\"fox_day\"], as_index=False ).count().rename(columns={\"time_diff\": \"points_this_day\"})\n",
    "\n",
    "max_window_per_day = foxes_all[[\"id\", \"time_diff\", \"fox_day\"]].groupby([\"id\",\"fox_day\"], as_index=False ).max().rename(columns={\"time_diff\": \"max_window\"})\n",
    "\n",
    "foxes_all_temp = pd.merge( foxes_all, points_per_day, left_on=[\"id\", \"fox_day\"], right_on=[\"id\", \"fox_day\"] )\n",
    "foxes_all_2 = pd.merge( max_window_per_day, foxes_all_temp , left_on=[\"id\", \"fox_day\"], right_on=[\"id\", \"fox_day\"] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we wanted to look into what we defined as the \"home range\" of a fox. \n",
    "This essentially meant the minimal convex polygon to include 95 % of the data points of the fox.\n",
    "\n",
    "Fortunately for me, the rest of the team had once more taken great care of it.\n",
    "\n",
    "So it was rather easy to construct said polygon for each fox and insert it into a new table, together with the area of the polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_homeranges = foxes_all.groupby([\"id\", \"sex\"], as_index=False).count()[[\"id\",\"sex\"]]\n",
    "\n",
    "foxes_homeranges[\"geometry\"] = [f4o.polygon_to_geojson(hr.hr_area(foxes_all.query('id ==@x'))) for x in foxes_homeranges.id ]\n",
    "foxes_homeranges[\"hr_area\"] = [hr.hr_area(foxes_all.query('id ==@x')).area for x in foxes_homeranges.id ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allowed for some analysis, like size comparision between the biggest and the smallest home range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_homeranges.hr_area.min() / foxes_homeranges.hr_area.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or analyzing the mean size of home ranges by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_homeranges.groupby(\"sex\", as_index = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we had a basic understanding of those home ranges, we wanted to see them on a map.\n",
    "But first I decided to create the shapely objects for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circles around the dens to see how those differ from home ranges. Not yet used for lack of ideas for radius\n",
    "# future work might define radius as distance from den to farthest point of polygon \n",
    "circle_all = Polygon()\n",
    "\n",
    "# all homeranges together as one Multipolygon.\n",
    "hr_all = Polygon()\n",
    "\n",
    "# Areas belonging to more than one home range\n",
    "intersect_all = Polygon()\n",
    "\n",
    "\n",
    "for fox_id in foxes_homeranges.id.unique():\n",
    "    fox_hr_poly = hr.hr_area(foxes_all.query(\"id == @fox_id\"))\n",
    "    x = hr_all.intersection(fox_hr_poly)\n",
    "    intersect_all = intersect_all.union(x)\n",
    "   # circle_all = circle_all.union(circle)\n",
    "    hr_all = hr_all.union(fox_hr_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preliminary work done, we wanted to see it on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1=KeplerGl(height=500)\n",
    "\n",
    "cols_df = [\"id\", \"geo_kepler_lat\", \"geo_kepler_lon\"]\n",
    "cols_geo = ['fox_day']\n",
    "\n",
    "\n",
    "for fox_id in foxes_all.id.unique():    \n",
    "    fox_hr_poly = hr.hr_area(foxes_all.query(\"id == @fox_id\"))\n",
    "    geojson = f4o.df_to_geojson_trip(foxes_all.query(\"id == @fox_id \"), cols_geo)\n",
    "    map1.add_data(data=geojson,name='Where does fox  ' + fox_id + ' trot?')\n",
    "    map1.add_data(data = f4o.polygon_to_geojson(fox_hr_poly), name='homerange' + fox_id)\n",
    "\n",
    "\n",
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next goal was to analyze how much distance a fox traveled per day.\n",
    "\n",
    "I concluded that this would only make sense if the time windows were small enough...if data points were two hours apart,\n",
    "euclidian distance between them would not plausibly represent the actual distance the fox traveled\n",
    "\n",
    "Maximal time windows of about 15 minutes seemed the best we could get, and I decided to add the safety requirement of \n",
    "at least 80 data points that day.\n",
    "This might seem redundant, but otherwise it would possible that a day with only one data point, 14 minutes after the day started,\n",
    "fulfilled the criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_relevant_days = foxes_all_2.query(\"max_window < 1000 and points_this_day > 80\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this reduced data set, it was possible to get min, max, mean and median of the travelled distance (in meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_relevant_days[[\"id\", \"fox_day\",\"travel_distance\"] ].groupby([\"id\", \"fox_day\"]).sum().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I created a table to compare those distances by month, to see if there were particulary \"active\" months.\n",
    "\n",
    "In our initial data, it seemed that in Juli, foxes travel only half the distance they travel in September.\n",
    "But our data was too sparse, with only 13 such \"day trips\" in July, so this was not necessarily representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = foxes_relevant_days[[\"id\", \"fox_day\", \"month\",\"travel_distance\"]].groupby([\"id\", \"fox_day\", \"month\"], as_index=False).sum()\n",
    "\n",
    "d = c[[ \"month\", \"travel_distance\"]].groupby([ \"month\"]).agg([np.min, np.max, np.mean, np.median, np.count_nonzero ], as_index=False)\n",
    "d.rename(columns={\"count_nonzero\": \"no_of_observations\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As further work, I decided to represent those \"day trips\" as polygons.\n",
    "\n",
    "Right now, use cases were limited.\n",
    "\n",
    "But one day, with more complete data, it would be possible to look how much the daily polygons of the foxes overlapped,\n",
    "to get an estimnation of they tended to avoid or meet each other.\n",
    "\n",
    "Also it seemed interesting to compare overlap of daily polygons for subsequent days - did they make the same route every day,\n",
    "or did they change the areas within their home ranges every day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "foxes_poly_day = gpd.GeoDataFrame(\n",
    "    foxes_relevant_days[[\"id\", \"fox_day\", \"x_\", \"y_\"]].groupby([\"id\", \"fox_day\"], as_index=False).apply(\n",
    "        lambda d: pd.Series(\n",
    "            {\n",
    "                \"geometry\": shapely.geometry.Polygon(\n",
    "                    d.loc[:, [\"x_\", \"y_\"]].values\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# appending the information as a new column, dividing value by 1.000.000 to get square kilometers rather than meters\n",
    "foxes_poly_day.eval( \"trip_area = geometry.area / 1000000\", inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes_poly_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample look at a polygon\n",
    "foxes_poly_day.geometry[23]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88fcde65eaa45fa38563b1be78b27e061faa45edeabc7876995c133cb7644015"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
