{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import geopandas as geopd\n",
    "import rasterio.rio\n",
    "import seaborn as sns\n",
    "import datetime as dt \n",
    "import h3\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, classification_report, roc_auc_score, make_scorer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from rasterio.plot import show\n",
    "\n",
    "import pyreadr\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = geopd.read_file(\"../data/final_shapefiles/foxes_modelling_all.shp\")\n",
    "df_resamp = geopd.read_file(\"../data/final_shapefiles/foxes_modelling_resamp.shp\")\n",
    "df_sample = geopd.read_file(\"../data/final_shapefiles/sample_points.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in a fist step, the category \"N\" is created twice\n",
    "\n",
    "df_sample[\"asp\"] = pd.cut(df_sample.aspect, \n",
    "                                bins = [-1.1,0,22.5,67.5,112.5,157.5,202.5,247.5,292.5,337.5,360],\n",
    "                                labels = [\"Flat\", \"N\", \"NE\", \"E\", \"SE\", \"S\", \"SW\", \"W\", \"NW\", \"N2\"])\n",
    "df_sample[\"asp\"] = df_sample.asp.replace(\"N2\",\"N\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_variables = [\"soil\", \"veg\", \"asp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_sample = pd.get_dummies(df_sample[cat_variables], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.concat([df_sample, categories_sample], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_enc = df_all.drop([\"veg\", \"soil\"], axis = 1)\n",
    "df_resamp_enc = df_resamp.drop([\"veg\", \"soil\"], axis = 1)\n",
    "df_sample_enc = df_sample.drop([\"veg\", \"soil\"], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Building Test and Train Set__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build a data frame with only the target and one with everything except the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all_enc.drop(\"target\", axis = 1)\n",
    "\n",
    "y = df_all_enc[\"target\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then these data frames are split in two data frames for the test data set and the train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_train, df_all_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = RSEED, test_size = 0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, for the training, we have to drop all columns from our feature data set, that we cannot and/or do not want to use for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_all_train.iloc[:,5:].drop([\"geometry\", \"area\", \"timestamp\", \"aspect\"], axis = 1)\n",
    "X_test = df_all_test.iloc[:,5:].drop([\"geometry\", \"area\", \"timestamp\", \"aspect\"], axis = 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __XGBoost without Scaling of Positive Weight__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we train a model without scaling of the positive weight, just do see, how it does on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state = RSEED)\n",
    "\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_train[\"pred\"] = xgb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_test[\"pred\"] = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, df_all_train.pred))\n",
    "print(classification_report(y_test, df_all_test.pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we would like to optimize for recall, this does not have a satisfying outcome. The model is predicting over 20 % of the fox locations wrong. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __XGBoost with Scaling of Positive Weight__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do something about that we scale up the positive weight, telling the model to put more weight on errors it does on the 1s in our target, so the known fox locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(scale_pos_weight = 100, random_state = RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Prediction of the Training and Test Data Set__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict both the probability and the binary response for later use in the depiction of our results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the prediction of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = xgb.predict_proba(X_train) # predict the probability of the outcome\n",
    "y_pred_train_class = xgb.predict(X_train) # predict the actual class of the outcome, when the threshold is 0.5. This threshold can be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pd.DataFrame(y_pred_train) # as we want to join the probability prediction to the data frame, we convert the predictions to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_train[\"pred_prob\"] = np.array(y_pred_train.iloc[:,1:]) # we then join the prediction to our training data frame\n",
    "df_all_train[\"pred\"] = xgb.predict(X_train) # the class outcome can be directly predicted into a new column of the data frame\n",
    "\n",
    "# we further build bins out of the probabilities that we can label as \"suitable\", \"intermediate suitable\" and \"unsuitable\" habitat for our foxes\n",
    "df_all_train[\"proba_bin\"] = pd.cut(df_all_train.pred_prob,\n",
    "            bins = [0, 0.6, 0.8, 1],\n",
    "            labels = [0, 0.8, 1]\n",
    ").astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the same steps for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = xgb.predict_proba(X_test) # predict the probability of the outcome\n",
    "y_pred_test_class = xgb.predict(X_test) # predict the actual class of the outcome, when the threshold is 0.5. This threshold can be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pd.DataFrame(y_pred_test) # as we want to join the probability prediction to the data frame, we convert the predictions to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_test[\"pred_prob\"] = np.array(y_pred_test.iloc[:,1:]) # we then join the prediction to our test data frame\n",
    "df_all_test[\"pred\"] = xgb.predict(X_test) # the class outcome can be directly predicted into a new column of the data frame\n",
    "\n",
    "# we further build bins out of the probabilities that we can label as \"suitable\", \"intermediate suitable\" and \"unsuitable\" habitat for our foxes\n",
    "df_all_test[\"proba_bin\"] = pd.cut(df_all_test.pred_prob,\n",
    "            bins = [0, 0.6, 0.8, 1],\n",
    "            labels = [0, 0.8, 1]\n",
    ").astype(\"float\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we print the classification report again. As we can see, our recall is much higher. (In the end we might just want to show recall and maybe accuracy/ AUC, should talk about that). With a recall of 1 on our training and a recall of 0.98 on our test set, we are confident in our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred_train_class))\n",
    "print(classification_report(y_test, y_pred_test_class))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us have a look into the importance of the different features for our XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.DataFrame(xgb.feature_importances_, index=X_train.columns, columns=[\"Importance\"])\n",
    "feat_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "feat_importances.plot(kind='bar', figsize=(8,6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, elevation is the most important feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_train, y_pred_train_class))\n",
    "print(roc_auc_score(y_test, y_pred_test_class))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a confusion matrix for the test results as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = confusion_matrix(y_test, y_pred_test_class)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(results, annot = True, cmap = \"Blues\")\n",
    "ax.set_title('XGBoost Confusion Matrix without Adjustments\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['No Fox','Fox'])\n",
    "ax.yaxis.set_ticklabels(['No Fox','Fox'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Predicting on regular Sample over whole Study Area__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are not allowed to show the locations of the foxes in the end, we now use our model to predict on a regular raster over the whole study area. First we have to drop some of the columns that are still in our sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pred = df_sample_enc.drop([\"x\", \"y\", \"geometry\", \"asp\", \"aspect\"], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to rename some of our columns in the sample point data frame, as they do not match the names in the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pred.rename(columns = {\"veg_Moist Shrub\" : \"veg_Moist\",\n",
    "                    \"soil_Peat(Turf)\" : \"soil_Peat(\",\n",
    "                    \"veg_Dry Shrub\" : 'veg_Dry Sh',\n",
    "                    \"veg_Grassland\" : \"veg_Grassl\",\n",
    "                    \"soil_Roesberg\" : \"soil_Roesb\"}, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then follow the same steps as above to predict the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sample = xgb.predict_proba(sample_pred)\n",
    "y_pred_sample = pd.DataFrame(y_pred_sample)\n",
    "y_pred_sample_1 = np.array(y_pred_sample.iloc[:,1:])\n",
    "df_sample_enc[\"pred_prob\"] = y_pred_sample_1\n",
    "df_sample_enc[\"pred\"] = xgb.predict(sample_pred)\n",
    "df_sample_enc[\"proba_bin\"] = pd.cut(df_sample_enc.pred_prob,\n",
    "            bins = [0, 0.6, 0.8, 1],\n",
    "            labels = [0, 0.8, 1]\n",
    ").astype(\"float\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Grid Search for XGBoost__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not really do that. But we could search for different parameters in a grid search. But for now you can more or less ignore this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_score(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred) + recall_score(y_true, y_pred)\n",
    "\n",
    "my_scorer = make_scorer(my_custom_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {\"scale_pos_weight\" : [1, 20, 40, 60, 80, 100]}\n",
    "param_grid = {\"scale_pos_weight\" : [3, 5, 8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_scoring(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    f1_pred = f1_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    score_sum = f1_pred + recall\n",
    "    return {\"f1\": f1_pred, \"recall\": recall, \"score_sum\": score_sum}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = GridSearchCV(estimator = xgb, param_grid = param_grid, verbose = 5, cv = 5, n_jobs = -1, scoring = [\"recall\", \"f1_macro\"], refit = \"recall\" + \"f1_macro\")\n",
    "grid = GridSearchCV(estimator = xgb, param_grid = param_grid, verbose = 5, cv = 5, n_jobs = -1, scoring = multi_scoring, refit = \"score_sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {\"scale_pos_weight\" : [1, 20, 40, 60, 80, 100]}\n",
    "param_grid = {\"scale_pos_weight\" : [3, 5, 8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = GridSearchCV(estimator = xgb, param_grid = param_grid, verbose = 5, cv = 5, n_jobs = -1, scoring = [\"recall\", \"f1_macro\"], refit = \"recall\" + \"f1_macro\")\n",
    "grid = GridSearchCV(estimator = xgb, param_grid = param_grid, verbose = 5, cv = 5, n_jobs = -1, scoring = multi_scoring, refit = \"score_sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {\"scale_pos_weight\" : [1, 20, 40, 60, 80, 100]}\n",
    "param_grid = {\"scale_pos_weight\" : [4, 5, 7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = GridSearchCV(estimator = xgb, param_grid = param_grid, verbose = 5, cv = 5, n_jobs = -1, scoring = [\"recall\", \"f1_macro\"], refit = \"recall\" + \"f1_macro\")\n",
    "grid = GridSearchCV(estimator = xgb, param_grid = param_grid, verbose = 5, cv = 5, n_jobs = -1, scoring = multi_scoring, refit = \"score_sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {\"scale_pos_weight\" : [1, 20, 40, 60, 80, 100]}\n",
    "param_grid = {\"scale_pos_weight\" : [5, 6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = GridSearchCV(estimator = xgb, param_grid = param_grid, verbose = 5, cv = 5, n_jobs = -1, scoring = [\"recall\", \"f1_macro\"], refit = \"recall\" + \"f1_macro\")\n",
    "grid = GridSearchCV(estimator = xgb, param_grid = param_grid, verbose = 5, cv = 5, n_jobs = -1, scoring = multi_scoring, refit = \"score_sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Trying to use H3 to convert Points to Hexagrid__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now just ignore this section and move one to the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_train.set_crs(3006, inplace = True)\n",
    "df_all_train.to_crs(4326, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_train[\"lon\"]  = df_all_train.geometry.x\n",
    "df_all_train[\"lat\"]  = df_all_train.geometry.y\n",
    "df_all_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(df, metric_col, x='lon', y='lat', marker='.', alpha=1, figsize=(16,12), colormap='viridis'):    \n",
    "    df.plot.scatter(x=x, y=y, c=metric_col, title=metric_col\n",
    "                    , edgecolors='none', colormap=colormap, marker=marker, alpha=alpha, figsize=figsize);\n",
    "    plt.xticks([], []); plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APERTURE_SIZE = 8\n",
    "hex_col = 'hex'+str(APERTURE_SIZE)\n",
    "\n",
    "# find hexs containing the points\n",
    "df_all_train[hex_col] = df_all_train.apply(lambda x: h3.geo_to_h3(x.lon,x.lat,APERTURE_SIZE),1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = df_all_train, x = \"proba_bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the points\n",
    "# df_all_train_g = df_all_train.groupby(hex_col).size().to_frame('pred').reset_index()\n",
    "df_all_train_g = df_all_train.groupby(hex_col).max().reset_index()\n",
    "\n",
    "#find center of hex for visualization\n",
    "df_all_train_g['lon'] = df_all_train_g[hex_col].apply(lambda x: h3.h3_to_geo(x)[0])\n",
    "df_all_train_g['lat'] = df_all_train_g[hex_col].apply(lambda x: h3.h3_to_geo(x)[1])\n",
    "\n",
    "# pltot the hexs\n",
    "plot_scatter(df_all_train_g, metric_col='pred_prob', marker='o',figsize=(20,18))\n",
    "plt.title('hex-grid: foxes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_train_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Plot of Prediction on whole area__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the prediction we did on the whole area set. We first build a function to plot our outcome later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(df, metric_col, x='lon', y='lat', marker='.', alpha=1, figsize=(16,12), colormap='viridis'):    \n",
    "    df.plot.scatter(x=x, y=y, c=metric_col, title=metric_col\n",
    "                    , edgecolors='none', colormap=colormap, marker=marker, alpha=alpha, figsize=figsize);\n",
    "    plt.xticks([], []); plt.yticks([], [])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we set and change the crs of our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_enc.set_crs(3006, inplace = True)\n",
    "df_sample_enc.to_crs(4326, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we extract the longitude and latitude from our geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_enc[\"lon\"]  = df_sample_enc.geometry.x\n",
    "df_sample_enc[\"lat\"]  = df_sample_enc.geometry.y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start using h3. With h3 we aggregate all of our points into hexagons of different sizes. We will use size 8, 9 or 10. I will plot examples for all 3 here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APERTURE_SIZE = 8\n",
    "hex_col = 'hex'+str(APERTURE_SIZE)\n",
    "\n",
    "# find hexs containing the points\n",
    "df_sample_enc[hex_col] = df_sample_enc.apply(lambda x: h3.geo_to_h3(x.lon,x.lat,APERTURE_SIZE),1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the points\n",
    "df_sample_enc_g8 = df_sample_enc.groupby(hex_col).mean().reset_index()\n",
    "\n",
    "#find center of hex for visualization\n",
    "df_sample_enc_g8['lon'] = df_sample_enc_g8[hex_col].apply(lambda x: h3.h3_to_geo(x)[0])\n",
    "df_sample_enc_g8['lat'] = df_sample_enc_g8[hex_col].apply(lambda x: h3.h3_to_geo(x)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pltot the hexs\n",
    "plot_scatter(df_sample_enc_g8, metric_col='pred_prob',figsize=(11,9), marker='h')\n",
    "plt.title('hex-grid: foxes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APERTURE_SIZE = 9\n",
    "hex_col = 'hex'+str(APERTURE_SIZE)\n",
    "\n",
    "# find hexs containing the points\n",
    "df_sample_enc[hex_col] = df_sample_enc.apply(lambda x: h3.geo_to_h3(x.lon,x.lat,APERTURE_SIZE),1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the points\n",
    "df_sample_enc_g9 = df_sample_enc.groupby(hex_col).mean().reset_index()\n",
    "\n",
    "#find center of hex for visualization\n",
    "df_sample_enc_g9['lon'] = df_sample_enc_g9[hex_col].apply(lambda x: h3.h3_to_geo(x)[0])\n",
    "df_sample_enc_g9['lat'] = df_sample_enc_g9[hex_col].apply(lambda x: h3.h3_to_geo(x)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pltot the hexs\n",
    "plot_scatter(df_sample_enc_g9, metric_col='pred_prob',figsize=(22,20), marker='h')\n",
    "plt.title('hex-grid: foxes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APERTURE_SIZE = 10\n",
    "hex_col = 'hex'+str(APERTURE_SIZE)\n",
    "\n",
    "# find hexs containing the points\n",
    "df_sample_enc[hex_col] = df_sample_enc.apply(lambda x: h3.geo_to_h3(x.lon,x.lat,APERTURE_SIZE),1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the points\n",
    "df_sample_enc_g = df_sample_enc.groupby(hex_col).mean().reset_index()\n",
    "\n",
    "#find center of hex for visualization\n",
    "df_sample_enc_g['lon'] = df_sample_enc_g[hex_col].apply(lambda x: h3.h3_to_geo(x)[0])\n",
    "df_sample_enc_g['lat'] = df_sample_enc_g[hex_col].apply(lambda x: h3.h3_to_geo(x)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pltot the hexs\n",
    "plot_scatter(df_sample_enc_g, metric_col='pred_prob',figsize=(40,38), marker='h')\n",
    "plt.title('hex-grid: foxes');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the ones above are plotted with the mean. The one below is plotted with the max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the points\n",
    "# df_sample_enc_g = df_sample_enc.groupby(\"hex8\").size().to_frame('pred').reset_index()\n",
    "df_sample_enc_g = df_sample_enc.groupby(\"hex8\").max().reset_index()\n",
    "\n",
    "#find center of hex for visualization\n",
    "df_sample_enc_g['lon'] = df_sample_enc_g[\"hex8\"].apply(lambda x: h3.h3_to_geo(x)[0])\n",
    "df_sample_enc_g['lat'] = df_sample_enc_g[\"hex8\"].apply(lambda x: h3.h3_to_geo(x)[1])\n",
    "\n",
    "# pltot the hexs\n",
    "plot_scatter(df_sample_enc_g, metric_col='pred_prob', marker='h',figsize=(11,9))\n",
    "plt.title('hex-grid: foxes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the points\n",
    "# df_sample_enc_g = df_sample_enc.groupby(\"hex8\").size().to_frame('pred').reset_index()\n",
    "df_sample_enc_g = df_sample_enc.groupby(\"hex8\").count().reset_index()\n",
    "df_sample_enc_g.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6a69aa757ec17a4e0946f75be1e0779f2abbf22d97369245d2f8ed69441e342"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
